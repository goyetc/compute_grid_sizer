{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pseudocode for calculator\n",
    "* define raw resources / node type \n",
    "* usable = raw-overhead\n",
    "* define desired hardware tier\n",
    "* total resources per execution = (hardware tier def + execution overhead) \n",
    "* max executions = int(min(usable cpu/total cpu per execution, usable mem/total mem per execution))\n",
    "* define overhead for cpu, memory\n",
    "* produce overhead metrics\n",
    "* define idle cpu, memory\n",
    "* produce utilization metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "######## Init ################\n",
    "\n",
    "#global node_overhead_cpu\n",
    "#global node_overhead_mem\n",
    "global exec_overhead_cpu\n",
    "global exec_overhead_mem\n",
    "\n",
    "#node_overhead_cpu = 1.5 #cores\n",
    "#node_overhead_mem = 2  #GiB\n",
    "\n",
    "exec_overhead_cpu = 1 #cores\n",
    "exec_overhead_mem = 1 #GiB\n",
    "\n",
    "req_cpu = sys.argv[1]\n",
    "req_mem = sys.argv[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allocatable memory and CPU resources\n",
    "Allocatable resources are calculated in the following way:\n",
    "\n",
    "Allocatable = Capacity - Reserved - Eviction Threshold\n",
    "\n",
    "For memory resources, GKE reserves the following:\n",
    "\n",
    "* 255 MiB of memory for machines with less than 1 GB of memory\n",
    "* 25% of the first 4GB of memory\n",
    "* 20% of the next 4GB of memory (up to 8GB)\n",
    "* 10% of the next 8GB of memory (up to 16GB)\n",
    "* 6% of the next 112GB of memory (up to 128GB)\n",
    "* 2% of any memory above 128GB\n",
    "Note: Prior to 1.12.0, machines with less than 1GB of memory are exempt from memory reservations.\n",
    "GKE reserves an additional 100 MiB of memory on each node for kubelet eviction.\n",
    "\n",
    "For CPU resources, GKE reserves the following:\n",
    "\n",
    "6% of the first core\n",
    "1% of the next core (up to 2 cores)\n",
    "0.5% of the next 2 cores (up to 4 cores)\n",
    "0.25% of any cores above 4 cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reserved_mem(mem):\n",
    "    \n",
    "    kubelet_eviction_reserve = .100\n",
    "    \n",
    "    if mem <=1.0:\n",
    "        #255 MiB of memory for machines with less than 1 GB of memory\n",
    "        reserved = 0.255\n",
    "    elif (mem >1.0 and mem<=4.0):\n",
    "        #25% of the first 4GB of memory\n",
    "        reserved = .25*mem\n",
    "    elif (mem >4.0 and mem <=8.0):\n",
    "        #20% of the next 4GB of memory (up to 8GB)\n",
    "        reserved = .25*(4.0) + .20*(mem-4.0)\n",
    "    elif (mem >8.0 and mem <=16.0):\n",
    "        #10% of the next 8GB of memory (up to 16GB)\n",
    "        reserved = .25*(4.0) + .20*(4.0) + .10*(mem-8.0)\n",
    "    elif (mem >16.0 and mem <=128.0):\n",
    "        #6% of the next 112GB of memory (up to 128GB)\n",
    "        reserved = .25*(4.0) + .20*(4.0) + .10*(8.0) + .06*(mem-16.0)\n",
    "    else: \n",
    "        #2% of any memory above 128GB\n",
    "        reserved = .25*(4.0) + .20*(4.0) + .10*(8.0) + .06*(112.0) + .02*(mem-128.0)\n",
    "    \n",
    "    node_overhead_mem = reserved + kubelet_eviction_reserve\n",
    "    return node_overhead_mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reserved_cpu(cpu):\n",
    "    if cpu <=1.0:\n",
    "        #6% of the first core\n",
    "        reserved = .06*cpu\n",
    "    elif (cpu >1.0 and cpu<=2.0):\n",
    "        #1% of the next core (up to 2 cores)\n",
    "        reserved = .06*1.0 + .01*(cpu-1.0)\n",
    "    elif (cpu >2.0 and cpu <=4.0):\n",
    "        #0.5% of the next 2 cores (up to 4 cores)\n",
    "        reserved = .06*1.0 + .01*(1.0) + .005*(cpu-2.0)\n",
    "    else: \n",
    "        reserved = .06*(1.0) + .01*(1.0) + .005*(2.0) + .0025*(cpu-4)\n",
    "    \n",
    "    node_overhead_cpu = reserved\n",
    "    return node_overhead_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Import Data ################\n",
    "\n",
    "df = pd.read_csv(sys.argv[3])\n",
    "hw_tier_catalogue = df[['Instance','vCPU*','Mem (GiB)']]\n",
    "\n",
    "print('number of node types to size with: '+str(len(hw_tier_catalogue)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### notes #############\n",
    "'''define raw resources / node type\n",
    "usable = raw-overhead\n",
    "define desired hardware tier\n",
    "total resources per execution = (hardware tier def + execution overhead)\n",
    "max executions = int(min(usable cpu/total cpu per execution, usable mem/total mem per execution))\n",
    "define overhead for cpu, memory\n",
    "produce overhead metrics\n",
    "define idle cpu, memory\n",
    "produce utilization metrics'''\n",
    "\n",
    "\n",
    "######### Functions ############\n",
    "\n",
    "def max_exec(hw_cpu, hw_mem, exec_cpu, exec_mem):\n",
    "    \n",
    "    usable_cpu = hw_cpu - node_overhead_cpu\n",
    "    #print(usable_cpu)\n",
    "    usable_mem = hw_mem - node_overhead_mem\n",
    "    #print(usable_mem)\n",
    "    \n",
    "    run_cpu = exec_cpu + exec_overhead_cpu\n",
    "    #print(run_cpu)\n",
    "    run_mem = exec_mem + exec_overhead_mem\n",
    "    #print(run_mem)\n",
    "    \n",
    "    execs = 0\n",
    "    \n",
    "    while (usable_cpu >= run_cpu and usable_mem >= run_mem): \n",
    "        \n",
    "        execs += 1\n",
    "\n",
    "        usable_cpu -= run_cpu\n",
    "        usable_mem -= run_mem\n",
    "   \n",
    "    remaining_cpu = usable_cpu\n",
    "    remaining_mem = usable_mem\n",
    "    \n",
    "    o_cpu = node_overhead_cpu + (execs*exec_overhead_cpu)\n",
    "    o_mem = node_overhead_mem + (execs*exec_overhead_mem)\n",
    "    \n",
    "    print('execs: '+str(execs))\n",
    "    print('remaining_cpu: '+str(remaining_cpu))\n",
    "    print('remaining_mem: '+str(remaining_mem))\n",
    "    print('total_cpu_overhead: '+str(o_cpu))\n",
    "    print('total_mem_overhead: '+str(o_mem))\n",
    "    \n",
    "    return execs, remaining_cpu, remaining_mem, o_cpu, o_mem\n",
    "\n",
    "def overhead(execs, exec_cpu, exec_mem):\n",
    "\n",
    "    if execs !=0:\n",
    "        o_cpu = node_overhead_cpu + (execs*exec_overhead_cpu)\n",
    "        o_mem = node_overhead_mem + (execs*exec_overhead_mem)\n",
    "        \n",
    "        print('total_cpu_overhead: '+str(o_cpu))\n",
    "\n",
    "        tot_cpu = execs * exec_cpu\n",
    "        print('total execution cores: '+str(tot_cpu))\n",
    "\n",
    "        tot_mem = execs * exec_mem\n",
    "\n",
    "        #cpu overhead / total_exec_corese\n",
    "        ratio_cpu = o_cpu/tot_cpu\n",
    "        print('overhead ratio, cpu: '+str(ratio_cpu))\n",
    "        ratio_mem = o_mem/tot_mem\n",
    "        \n",
    "    else: #temp set to 100% overhead\n",
    "        ratio_cpu = 1\n",
    "        ratio_mem = 1\n",
    "    \n",
    "    return ratio_cpu, ratio_mem\n",
    "\n",
    "def utilization(hw_cpu, hw_mem, remaining_cpu, remaining_mem):\n",
    "    #utilization = (exec_resource_def - idle _resource) / exec_resource_def\n",
    "    util_cpu = (hw_cpu - remaining_cpu)/hw_cpu\n",
    "    util_mem = (hw_mem - remaining_mem)/hw_mem\n",
    "    \n",
    "    return util_cpu, util_mem\n",
    "\n",
    "def node_sizing(requested_cpu, requested_mem, hw_tier_data):\n",
    "    \n",
    "    df_results = pd.DataFrame(columns=['node_size', 'max_executions', 'overhead_ratio_cpu', 'overhead_ratio_mem', \n",
    "                                   'util_ratio_cpu', 'util_ratio_mem', 'efficiency_metric'])\n",
    "    \n",
    "    for i in range(len(hw_tier_data)):\n",
    "        hw_cpu = hw_tier_data.iloc[i,1]\n",
    "        #print(hw_cpu)\n",
    "        hw_mem = hw_tier_data.iloc[i,2]\n",
    "        #print(hw_mem)\n",
    "        \n",
    "        #Calculate node overheads for usable resources\n",
    "        #Note: updated with GKE overhead details from: https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-architecture#node_allocatable\n",
    "        #node_overhead_cpu = 1.5 #cores\n",
    "        #node_overhead_mem = 2  #GiB\n",
    "        node_overhead_cpu = reserved_cpu(hw_cpu)\n",
    "        node_overhead_mem = reserved_mem(hw_mem)\n",
    "        \n",
    "        usable_cpu = hw_cpu - node_overhead_cpu\n",
    "        usable_mem = hw_mem - node_overhead_mem\n",
    "        \n",
    "        if (usable_cpu > requested_cpu and usable_mem > requested_mem):\n",
    "                        \n",
    "            print('core count for eval: '+str(hw_cpu))\n",
    "            print('memory for eval (GB): '+str(hw_mem))\n",
    "            \n",
    "            execs, remaining_cpu, remaining_mem, o_cpu, o_mem = max_exec(hw_cpu, hw_mem, requested_cpu, requested_mem)\n",
    "        \n",
    "            overhead_cpu, overhead_mem = overhead(execs, requested_cpu, requested_mem)\n",
    "        \n",
    "            util_cpu, util_mem = utilization(hw_cpu, hw_mem, remaining_cpu, remaining_mem)\n",
    "        \n",
    "            eff_cpu = util_cpu/overhead_cpu\n",
    "            eff_mem = util_mem/overhead_mem\n",
    "        \n",
    "            efficiency_metric = eff_cpu + eff_mem\n",
    "        \n",
    "            df_result = pd.DataFrame({'node_size':hw_tier_data.iloc[i,0],\n",
    "                                      'max_executions':execs,\n",
    "                                      'overhead_ratio_cpu': overhead_cpu,\n",
    "                                      'overhead_ratio_mem': overhead_mem,\n",
    "                                      'util_ratio_cpu': util_cpu,\n",
    "                                      'util_ratio_mem': util_mem,\n",
    "                                      'efficiency_metric': efficiency_metric}, index = [0])\n",
    "        \n",
    "            #print(df_result.shape)\n",
    "        \n",
    "            df_results = df_results.append(df_result, ignore_index = True)\n",
    "            \n",
    "    #print(df_results.shape)\n",
    "        \n",
    "    return df_results\n",
    "\n",
    "\n",
    "########### Call function ##############\n",
    "\n",
    "results = node_sizing(req_cpu, req_mem, df)\n",
    "\n",
    "results = results.sort_values(['max_executions', 'efficiency_metric'], ascending=[False, False]).reset_index(drop=True)\n",
    "\n",
    "results.to_html(os.environ['DOMINO_WORKING_DIR']+'/results/node_recommendations_{}_{}.html'.format(req_cpu, req_mem))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
